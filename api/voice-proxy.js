/***************************************************************
 *  Allen MultiLing âˆ AI â€” Whisper Proxy v12.0.8
 *  Build: 2025-12-08 (Asia/Taipei)
 *
 *  ğŸ”Š åŠŸèƒ½èªªæ˜
 *    - æ¥æ”¶ GAS å‚³ä¾†çš„èªéŸ³ Base64
 *    - å‘¼å« OpenAI Audio APIï¼ˆWhisper / gpt-4o-transcribe ç­‰ï¼‰
 *    - å›å‚³ç´”æ–‡å­—é€å­—ç¨¿ï¼ˆæ”¯æ´ transcribe / translateï¼‰
 *
 *  ğŸ“¦ éœ€è¨­å®šçš„ Vercel Environment Variables
 *    - WHISPER_API_KEY  : çµ¦ GAS çš„ã€ŒèªéŸ³å¤–æ›é‡‘é‘°ã€ï¼Œç”¨ä¾†é©—è­‰ Proxy å‘¼å«
 *    - WHISPER_MODEL    : Whisper / Transcribe æ¨¡å‹åç¨±ï¼Œä¾‹å¦‚ï¼š
 *                         whisper-1 æˆ– gpt-4o-transcribe
 *    - OPENAI_API_KEY   : ä½ çš„ OpenAI é‡‘é‘°ï¼ˆsk-proj-xxxxï¼‰
 *
 *  ğŸ” GAS Script Properties å°æ‡‰
 *    - VOICE_EXT_URL  = https://allen-multiling-proxy.vercel.app/api/voice-proxy
 *    - AUDIO_API_KEY  = å’Œ WHISPER_API_KEY ç›¸åŒçš„ä¸€çµ„å­—ä¸²
 *
 *  ğŸ“¥ è«‹æ±‚æ ¼å¼ï¼ˆPOST /api/voice-proxyï¼‰
 *    {
 *      "key"        : "AllenMultiLing-WhisperKey-2025",
 *      "audioBase64": "<m4a/mp3 ä¹‹ Base64 å­—ä¸²>",
 *      "mimeType"   : "audio/m4a",
 *      "language"   : "th",              // å¯é¸ï¼ŒBCP-47ï¼›transcribe æ™‚å¯æŒ‡å®š
 *      "task"       : "transcribe"       // å¯é¸ï¼štranscribe | translateï¼ˆé è¨­ transcribeï¼‰
 *    }
 *
 *  ğŸ“¤ å›æ‡‰æ ¼å¼ï¼ˆæˆåŠŸï¼‰
 *    {
 *      "ok"  : true,
 *      "text": "<è¾¨è­˜å¾Œæ–‡å­—>",
 *      "raw" : { ...OpenAI åŸå§‹å›å‚³ JSON... }
 *    }
 *
 *  ğŸ“¤ å›æ‡‰æ ¼å¼ï¼ˆå¸¸è¦‹éŒ¯èª¤ï¼‰
 *    { "ok": false, "error": "METHOD_NOT_ALLOWED" }
 *    { "ok": false, "error": "INVALID_PROXY_KEY" }
 *    { "ok": false, "error": "MISSING_AUDIO_BASE64" }
 *    { "ok": false, "error": "MISSING_OPENAI_API_KEY" }
 *    { "ok": false, "error": "OPENAI_ERROR", "status": 400/401/500..., "detail": ... }
 *    { "ok": false, "error": "INTERNAL_ERROR", "detail": "..." }
 ***************************************************************/

export default async function handler(req, res) {
  // åªå…è¨± POST
  if (req.method !== 'POST') {
    res.status(405).json({ ok: false, error: 'METHOD_NOT_ALLOWED' });
    return;
  }

  try {
    // --- è§£æ Body ----------------------------------------------------------
    const bodyRaw = typeof req.body === 'string' ? req.body : JSON.stringify(req.body || {});
    const body = bodyRaw ? JSON.parse(bodyRaw) : {};

    const {
      key,
      audioBase64,
      mimeType,
      language,
      task,
    } = body;

    // --- Proxy é‡‘é‘°é©—è­‰ï¼ˆGAS â†” Vercelï¼‰--------------------------------------
    const proxyKey = process.env.WHISPER_API_KEY;
    if (!proxyKey) {
      res.status(500).json({
        ok: false,
        error: 'MISSING_WHISPER_API_KEY',
        detail: 'WHISPER_API_KEY is not set in environment variables.',
      });
      return;
    }

    if (!key || key !== proxyKey) {
      res.status(401).json({ ok: false, error: 'INVALID_PROXY_KEY' });
      return;
    }

    // --- åŸºæœ¬åƒæ•¸æª¢æŸ¥ ------------------------------------------------------
    if (!audioBase64 || typeof audioBase64 !== 'string' || audioBase64.trim() === '') {
      res.status(400).json({ ok: false, error: 'MISSING_AUDIO_BASE64' });
      return;
    }

    const openaiKey = process.env.OPENAI_API_KEY;
    if (!openaiKey) {
      res.status(500).json({
        ok: false,
        error: 'MISSING_OPENAI_API_KEY',
        detail: 'OPENAI_API_KEY is not set in environment variables.',
      });
      return;
    }

    const model = process.env.WHISPER_MODEL || 'whisper-1';
    const useTask = task === 'translate' ? 'translate' : 'transcribe';

    // --- æº–å‚™é€çµ¦ OpenAI çš„ multipart/form-data ----------------------------
    const buffer = Buffer.from(audioBase64, 'base64');
    const ext =
      (mimeType && mimeType.includes('/'))
        ? mimeType.split('/')[1]
        : 'm4a';
    const filename = `audio.${ext}`;

    const form = new FormData();
    const blob = new Blob([buffer], { type: mimeType || 'audio/m4a' });

    form.append('file', blob, filename);
    form.append('model', model);

    // transcribe å¯ä»¥å¸¶å…¥ languageï¼Œtranslate å‰‡è®“æ¨¡å‹è‡ªåˆ¤
    if (language && useTask === 'transcribe') {
      form.append('language', language);
    }

    const endpoint =
      useTask === 'translate'
        ? 'https://api.openai.com/v1/audio/translations'
        : 'https://api.openai.com/v1/audio/transcriptions';

    // --- å‘¼å« OpenAI Audio API ---------------------------------------------
    const apiRes = await fetch(endpoint, {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${openaiKey}`,
      },
      body: form,
    });

    const text = await apiRes.text();
    let data;
    try {
      data = JSON.parse(text);
    } catch (e) {
      data = null;
    }

    if (!apiRes.ok) {
      res.status(apiRes.status).json({
        ok: false,
        error: 'OPENAI_ERROR',
        status: apiRes.status,
        detail: data || text,
      });
      return;
    }

    const transcript = (data && data.text) || '';

    res.status(200).json({
      ok: true,
      text: transcript,
      raw: data,
    });
  } catch (err) {
    console.error('[Whisper Proxy] INTERNAL_ERROR', err);
    res.status(500).json({
      ok: false,
      error: 'INTERNAL_ERROR',
      detail: String(err && err.message ? err.message : err),
    });
  }
}
